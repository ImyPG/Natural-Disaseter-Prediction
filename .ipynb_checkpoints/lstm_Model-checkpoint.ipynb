{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6762dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LONG SHORT TERM MEMORY\n",
    "#A useful algorithm that captures complex relationships in time series data. \n",
    "#The technique is called long short-term memory (LSTM). \n",
    "#The work employs this method in two cases of study; the first learns all the datasets in one model, \n",
    "#the second case learns the correlations on two divided groups considering their range of magnitude. \n",
    "#The results show that learning decomposed datasets gives more well-functioning predictions since it exploits \n",
    "#the nature of each type of events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647f7867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove tenserflow info from console\n",
    "import os\n",
    "from math import sqrt\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('INFO')\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Bidirectional\n",
    "from keras.layers import Dropout\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c3e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\".csv\",  delimiter=',', parse_dates=['Date'], index_col=\"Date\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdb629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(df) * 0.9)\n",
    "test_size = len(df) - train_size\n",
    "train, test = df.iloc[0:train_size], df.iloc[train_size:len(df)]\n",
    "print(len(train), len(test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de66d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_columns = ['Latitude', 'Longitude', 'Depth']\n",
    "\n",
    "f_transformer = RobustScaler()\n",
    "cnt_transformer = RobustScaler()\n",
    "\n",
    "f_transformer = f_transformer.fit(train[f_columns].to_numpy())\n",
    "cnt_transformer = cnt_transformer.fit(train[['Magnitude']])\n",
    "\n",
    "train.loc[:, f_columns] = f_transformer.transform(train[f_columns].to_numpy())\n",
    "train['Magnitude'] = cnt_transformer.transform(train[['Magnitude']])\n",
    "\n",
    "test.loc[:, f_columns] = f_transformer.transform(test[f_columns].to_numpy())\n",
    "test['Magnitude'] = cnt_transformer.transform(test[['Magnitude']])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47c454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        Xs.append(v)\n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "time_steps = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120ae043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to [samples, time_steps, n_features]\n",
    "X_train, y_train = create_dataset(train, train['Magnitude'], time_steps)\n",
    "X_test, y_test = create_dataset(test, test['Magnitude'], time_steps)\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802553a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(units=128, input_shape=(X_train.shape[1], X_train.shape[2]))))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(units=1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93e3685",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,epochs=30, batch_size=32, validation_split=0.1, shuffle=False)\n",
    "\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002d9bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_inv = cnt_transformer.inverse_transform(y_pred)\n",
    "\n",
    "y_test_inv = cnt_transformer.inverse_transform(y_test.reshape(1, -1))\n",
    "y_train_inv = cnt_transformer.inverse_transform(y_train.reshape(1, -1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d078d939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert y_test and y_pred to dataframe\n",
    "y_df = pd.DataFrame(y_test_inv.T, columns=['y_test_mag'])\n",
    "y_df['y_pred_mag'] = y_pred_inv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71603734",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0, len(y_train)), y_train_inv.flatten(), 'g', label=\"history\")\n",
    "plt.plot(np.arange(len(y_train), len(y_train) + len(y_test)), y_test_inv.flatten(), marker='.', label=\"true\")\n",
    "plt.plot(np.arange(len(y_train), len(y_train) + len(y_test)), y_pred_inv.flatten(), 'r', label=\"prediction\")\n",
    "plt.ylabel('Magnitude')\n",
    "plt.xlabel('Time Step')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec95dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test_inv.flatten(), marker='.', label=\"true\")\n",
    "plt.plot(y_pred_inv.flatten(), 'r', label=\"prediction\")\n",
    "plt.ylabel('Magnitude')\n",
    "plt.xlabel('Time Step')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2177d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "rmse_lstm_pred = sqrt(mean_squared_error(y_df['y_test_mag'], y_df['y_pred_mag']))\n",
    "print(\"LSTM RMSE\", rmse_lstm_pred)\n",
    "lstm_score = r2_score(y_df['y_test_mag'], y_df['y_pred_mag'])\n",
    "print(\"LSTM r2 score \", lstm_score)\n",
    "lstm_ms = mean_squared_error(y_df['y_test_mag'], y_df['y_pred_mag'])\n",
    "print(\"LSTM mean squared error \", lstm_ms)\n",
    "lstm_m = mean_absolute_error(y_df['y_test_mag'], y_df['y_pred_mag'])\n",
    "print(\"LSTM mean absolute error \", lstm_m)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d8a544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/demand-prediction-with-lstms-using-tensorflow-2-and-keras-in-python-1d1076fc89a0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279a68d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df,test_df = data_df[0:-len(df_targets)], data_df[-len(df_targets):]\n",
    "#\n",
    "# x = data_df.iloc[:,:-1].values # inputs\n",
    "# y = data_df.iloc[:,-1].values  # target\n",
    "#\n",
    "# sc = StandardScaler()\n",
    "# x_scale = sc.fit_transform(x)\n",
    "# y_scale = sc.fit_transform(y.reshape(-1,1))\n",
    "#\n",
    "# df_targets = data_df[\"2020-03-31 00:00:00 \":\"2020-04-01 00:00:00\"]\n",
    "# x_train = data_df.iloc[0:-len(df_targets), :-1]\n",
    "# y_train = data_df.iloc[:-len(df_targets), -1]\n",
    "# x_test = data_df.iloc[-len(df_targets):, :-1]\n",
    "# y_test = data_df.iloc[-len(df_targets):, -1]\n",
    "# print(x_train.shape, y_train.shape)\n",
    "# print(x_test.shape, y_test.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
